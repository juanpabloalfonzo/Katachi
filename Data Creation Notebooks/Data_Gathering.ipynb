{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c8752d1",
   "metadata": {},
   "source": [
    "# Importing Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ce845f",
   "metadata": {},
   "source": [
    "Notebook used to generate all the data you find in the Catalogues in the Catalogues folder of this repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47163837",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;34m[INFO]: \u001b[0mNo release version set. Setting default to DR17\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mpath /home/juanpabloalfonzo/sas/dr17/manga/spectro/redux/v3_1_1/drpall-v3_1_1.fits cannot be found. Setting drpall to None.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mpath /home/juanpabloalfonzo/sas/dr17/manga/spectro/analysis/v3_1_1/3.1.0/dapall-v3_1_1-3.1.0.fits cannot be found. Setting dapall to None.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mpath /home/juanpabloalfonzo/sas/dr17/manga/spectro/redux/v3_1_1/drpall-v3_1_1.fits cannot be found. Setting drpall to None.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mpath /home/juanpabloalfonzo/sas/dr17/manga/spectro/analysis/v3_1_1/3.1.0/dapall-v3_1_1-3.1.0.fits cannot be found. Setting dapall to None.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Loading needed modules and classes/functions \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os, time, shutil, hickle\n",
    "from tqdm import tqdm\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=1.8)\n",
    "sns.set_style('white')\n",
    "from PIL import Image\n",
    "\n",
    "#------------------------------------------\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import ImageFolder \n",
    "from torchvision.io import read_image, decode_image\n",
    "from torchvision.models import vgg19\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "\n",
    "#-------------------------------------------\n",
    "import marvin\n",
    "from marvin.tools.maps import Maps\n",
    "# from marvin.tools.image import Image\n",
    "from marvin.utils.general.images import get_images_by_list\n",
    "from marvin import config\n",
    "from marvin.tools.cube import Cube\n",
    "\n",
    "#-------------------------------------------\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#-------------------------------------------\n",
    "from PIL import Image as image_PIL\n",
    "import PIL \n",
    "from PIL import ImageShow\n",
    "\n",
    "#-------------------------------------------\n",
    "from pytorch_grad_cam import GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, EigenGradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "\n",
    "from astropy.io import fits\n",
    "\n",
    "#set config attributes and turn on global downloads of Marvin data\n",
    "config.setRelease('DR17')\n",
    "config.mode = 'local'\n",
    "config.download = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d2b5ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = #########Put the directory to the folder where you gitclone the directory to here########## \n",
    "data = fits.open(work_dir +'VACs/SDSS17Pipe3D_v3_1_1.fits')\n",
    "data_gz = fits.open(work_dir +'VACs/MaNGA_gz-v2_0_1.fits')\n",
    "data_gema = fits.open(work_dir+'VACs/GEMA_2.0.2.fits')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e70c6f7",
   "metadata": {},
   "source": [
    "# Morphology Data Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a175be53",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = data[1]\n",
    "table_gz = data_gz[1].data\n",
    "table_gema1 = data_gema[1].data\n",
    "table_gema12 = data_gema[12].data\n",
    "table_gema14 = data_gema[14].data\n",
    "\n",
    "\n",
    "manga_id = []\n",
    "log_mstar = []\n",
    "log_sfr = []\n",
    "redshift = []\n",
    "sersic_n =[]\n",
    "t50 = []\n",
    "d4000 = []\n",
    "Av=[]\n",
    "Z=[]\n",
    "RA_pipe3d=[]\n",
    "DEC_pipe3d=[]\n",
    "\n",
    "for i in range(len(table.data)):\n",
    "    manga_id.append(table.data[i][4])\n",
    "    log_mstar.append(table.data[i][12])\n",
    "    log_sfr.append(table.data[i][7])\n",
    "    redshift.append(table.data[i][177])\n",
    "    sersic_n.append(table.data[i][512])\n",
    "    t50.append(table.data[i][115])\n",
    "    d4000.append(table.data[i][456])\n",
    "    Av.append(table.data[i][173])\n",
    "    Z.append(table.data[i][28])\n",
    "    RA_pipe3d.append(table.data[i][5])\n",
    "    DEC_pipe3d.append(table.data[i][6])\n",
    "\n",
    "#Cleaning out repeat IDs \n",
    "manga_id_unique, unique_index = np.unique(manga_id, return_index=True)\n",
    "\n",
    "manga_id = np.array(manga_id,dtype=str)[unique_index]\n",
    "log_mstar = np.array(log_mstar)[unique_index]\n",
    "log_sfr = np.array(log_sfr)[unique_index]\n",
    "redshift = np.array(redshift)[unique_index]\n",
    "sersic_n =np.array(sersic_n)[unique_index]\n",
    "t50 = np.array(t50)[unique_index]\n",
    "d4000 = np.array(d4000)[unique_index]\n",
    "Av= np.array(Av)[unique_index]\n",
    "Z= np.array(Z)[unique_index]\n",
    "RA_pipe3d= np.array(RA_pipe3d)[unique_index]\n",
    "DEC_pipe3d= np.array(DEC_pipe3d)[unique_index]\n",
    "\n",
    "\n",
    "\n",
    "galaxy_zoo_mangaid=[]\n",
    "for i in range(len(table_gz)):\n",
    "  galaxy_zoo_mangaid.append(table_gz[i][1])\n",
    "\n",
    "gema_mangaid_table1=[]\n",
    "for i in range(len(table_gema1)):\n",
    "  gema_mangaid_table1.append(table_gema1[i][0])\n",
    "\n",
    "gema_mangaid_table12=[]\n",
    "for i in range(len(table_gema12)):\n",
    "  gema_mangaid_table12.append(table_gema12[i][0])\n",
    "\n",
    "gema_mangaid_table14=[]\n",
    "for i in range(len(table_gema14)):\n",
    "  gema_mangaid_table14.append(table_gema14[i][0])\n",
    "\n",
    "\n",
    "\n",
    "matching_mangaids_gz=[]\n",
    "matching_mangaids_gema_table1=[]\n",
    "matching_mangaids_gema_table12=[]\n",
    "matching_mangaids_gema_table14=[]\n",
    "\n",
    "\n",
    "matching_index0=[]\n",
    "matching_index1=[]\n",
    "matching_index2=[]\n",
    "matching_index3=[]\n",
    "\n",
    "matching_index_gz=[]\n",
    "matching_index_gema_table1=[]\n",
    "matching_index_gema_table12=[]\n",
    "matching_index_gema_table14=[]\n",
    "\n",
    "for i in range (len(manga_id)):\n",
    "  for j in range(len(galaxy_zoo_mangaid)): \n",
    "    if manga_id[i] == galaxy_zoo_mangaid[j]: \n",
    "      matching_mangaids_gz.append(manga_id[i])\n",
    "      matching_index_gz.append(j)\n",
    "      matching_index0.append(i)\n",
    "\n",
    "for i in range (len(manga_id)):\n",
    "  for r in range(len(gema_mangaid_table1)):\n",
    "    if manga_id[i]==gema_mangaid_table1[r]:\n",
    "      matching_mangaids_gema_table1.append(manga_id[i])\n",
    "      matching_index_gema_table1.append(r)\n",
    "      matching_index1.append(i)\n",
    "\n",
    "for i in range (len(manga_id)):\n",
    "  for p in range(len(gema_mangaid_table12)):\n",
    "    if manga_id[i]==gema_mangaid_table12[p]:\n",
    "      matching_mangaids_gema_table12.append(manga_id[i])\n",
    "      matching_index_gema_table12.append(p)\n",
    "      matching_index2.append(i)\n",
    "\n",
    "for i in range (len(manga_id)):\n",
    "  for q in range(len(gema_mangaid_table14)):\n",
    "    if manga_id[i]==gema_mangaid_table14[q]:\n",
    "      matching_mangaids_gema_table14.append(manga_id[i])\n",
    "      matching_index_gema_table14.append(q)\n",
    "      matching_index3.append(i)\n",
    "\n",
    "\n",
    "#Galaxy Zoo using weight fraction and on the positive statement (i.e yes bar and not no bar)\n",
    "spirals=[]\n",
    "bars=[]\n",
    "irregular_features=[] #called odd_feature_irregular in data model \n",
    "edge_on=[]  \n",
    "bulge=[] #Dominant bulge \n",
    "RA_gz=[]\n",
    "DEC_gz=[]\n",
    "redshift_gz=[]\n",
    "smooth=[]\n",
    "merger_gz=[]\n",
    "gz_id_test=[]\n",
    "\n",
    "\n",
    "i=0\n",
    "for k in range (len(manga_id)):\n",
    "  if manga_id[k] in galaxy_zoo_mangaid: \n",
    "    j=matching_index_gz[i]\n",
    "    gz_id_test.append(table_gz[j][1])\n",
    "    bars.append(table_gz[j][56])\n",
    "    spirals.append(table_gz[j][70])\n",
    "    bulge.append(table_gz[j][102])\n",
    "    irregular_features.append(table_gz[j][166])\n",
    "    edge_on.append(table_gz[j][42])\n",
    "    RA_gz.append(table_gz[j][4])\n",
    "    DEC_gz.append(table_gz[j][5])\n",
    "    redshift_gz.append(table_gz[j][9])\n",
    "    smooth.append(table_gz[j][22])\n",
    "    merger_gz.append(table_gz[j][174])\n",
    "    i=i+1\n",
    "  else:\n",
    "    gz_id_test.append('nan')\n",
    "    bars.append(np.nan)\n",
    "    spirals.append(np.nan)\n",
    "    bulge.append(np.nan)\n",
    "    irregular_features.append(np.nan)\n",
    "    edge_on.append(np.nan)\n",
    "    RA_gz.append(np.nan)\n",
    "    DEC_gz.append(np.nan)\n",
    "    redshift_gz.append(np.nan)\n",
    "    smooth.append(np.nan)\n",
    "    merger_gz.append(np.nan)\n",
    "\n",
    "#GEMA VAC\n",
    "\n",
    "\n",
    "\n",
    "i=0 \n",
    "p_merger = []\n",
    "over_density = []\n",
    "local_density = []\n",
    "z_completeness = []\n",
    "\n",
    "\n",
    "for k in range(len(manga_id)):\n",
    "  if manga_id[k] in gema_mangaid_table1:\n",
    "    j= matching_index_gema_table1[i]\n",
    "    z_completeness.append(table_gema1[j][2])\n",
    "    i=i+1 \n",
    "  else:\n",
    "    z_completeness.append(np.nan)\n",
    "\n",
    "i=0\n",
    "for k in range(len(manga_id)):\n",
    "  if manga_id[k] in gema_mangaid_table12:\n",
    "    j=matching_index_gema_table12[i]\n",
    "    p_merger.append(table_gema12[j][1])\n",
    "    i=i+1\n",
    "  else:\n",
    "    p_merger.append(np.nan)\n",
    "    \n",
    "i=0\n",
    "for k in range(len(manga_id)):\n",
    "  if manga_id[k] in gema_mangaid_table14:\n",
    "    j = matching_index_gema_table14[i]\n",
    "    over_density.append(table_gema14[j][1])\n",
    "    local_density.append(table_gema14[j][2])\n",
    "    i=i+1\n",
    "  else:\n",
    "    over_density.append(np.nan)\n",
    "    local_density.append(np.nan)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b10a0b79",
   "metadata": {},
   "source": [
    "Getting t50 values from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5828cab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the one-layer linear neural network class\n",
    "class LinearNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LinearNet, self).__init__()\n",
    "        self.linear_in = nn.Linear(input_size, hidden_size)\n",
    "        self.linear_out = nn.Linear(hidden_size, output_size)\n",
    "        self.linear = nn.Linear(hidden_size,hidden_size)\n",
    "        self.activation = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # print(x.size())\n",
    "        out = self.linear_in(x)\n",
    "        # print(out.size())\n",
    "        out = self.activation(out)\n",
    "        out = self.linear(out)\n",
    "        out = self.activation(out)\n",
    "        out = self.linear(out)\n",
    "        out = self.activation(out)\n",
    "        out = self.linear(out)\n",
    "        out = self.activation(out)\n",
    "        # out = self.linear(out)\n",
    "        # out = self.activation(out)\n",
    "        out = self.linear_out(out)\n",
    "        return out\n",
    "\n",
    "# Example usage\n",
    "input_size = 2\n",
    "hidden_size = 100\n",
    "output_size = 1\n",
    "\n",
    "\n",
    "# Create an instance of the LinearNet\n",
    "d4000_to_t50 = LinearNet(input_size, hidden_size, output_size).to('cuda')\n",
    "\n",
    "\n",
    "d4000_to_t50.load_state_dict(torch.load(work_dir+'models/d400_to_t50.pytorch'))\n",
    "\n",
    "\n",
    "input_data_plot = torch.stack((torch.tensor(d4000,dtype=torch.float32),torch.tensor(log_sfr,dtype=torch.float32)-torch.tensor(log_mstar,dtype=torch.float32)),dim=1)\n",
    "input_data_plot = input_data_plot.reshape(input_data_plot.shape[0],input_data_plot.shape[1])\n",
    "\n",
    "t50_output = d4000_to_t50(input_data_plot.to('cuda'))\n",
    "t50_output = t50_output.detach().cpu().numpy().flatten()\n",
    "t50_output = (t50_output*13.6) #to make it in units of Gyr \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93d7f9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(src_image, size=(256,256), bg_color=\"black\"): \n",
    "    \n",
    "    # resize the image so the longest dimension matches our target size\n",
    "    src_image.thumbnail(size, Image.ANTIALIAS)\n",
    "    \n",
    "    # Create a new square background image\n",
    "    new_image = Image.new(\"RGB\", size, bg_color)\n",
    "    \n",
    "    # Paste the resized image into the center of the square background\n",
    "    new_image.paste(src_image, (int((size[0] - src_image.size[0]) / 2), int((size[1] - src_image.size[1]) / 2)))\n",
    "  \n",
    "    # return the resized image\n",
    "    return new_image\n",
    "\n",
    "def load_image_data(idlist, size=(256,256), bg_color=\"black\"):\n",
    "    img = Image.open(work_dir+'images (DR17)/'+idlist+'.png')\n",
    "    img_sized = resize_image(img, size=size, bg_color=bg_color)\n",
    "    return img_sized\n",
    "\n",
    "def find_file(filename, directory1, directory2):\n",
    "    # Check if the file exists in the first directory\n",
    "    file_path = os.path.join(directory1, filename)\n",
    "    if os.path.exists(file_path):\n",
    "        return np.load(file_path)\n",
    "\n",
    "    # If the file is not found in the first directory, check the second directory\n",
    "    file_path = os.path.join(directory2, filename)\n",
    "    if os.path.exists(file_path):\n",
    "        return np.load(file_path)\n",
    "\n",
    "    # If the file is not found in either directory, return None\n",
    "    return None\n",
    "\n",
    "def find_file_txt(filename, directory1, directory2):\n",
    "    # Check if the file exists in the first directory\n",
    "    file_path = os.path.join(directory1, filename)\n",
    "    if os.path.exists(file_path):\n",
    "        category.append('Train')\n",
    "        return np.loadtxt(file_path)\n",
    "\n",
    "    # If the file is not found in the first directory, check the second directory\n",
    "    file_path = os.path.join(directory2, filename)\n",
    "    if os.path.exists(file_path):\n",
    "        category.append('Test')\n",
    "        return np.loadtxt(file_path)\n",
    "\n",
    "    # If the file is not found in either directory, return None\n",
    "    category.append('None')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ff872a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's get images for each galaxy\n",
    "gal_ids = manga_id\n",
    "for i in tqdm(range(len(gal_ids))):\n",
    "    try:\n",
    "        im = Image(mangaid = gal_ids[i])\n",
    "\n",
    "        # generate a new image\n",
    "        # inputs are height and width in arcsec, and a arcsec/pixel scale\n",
    "        im.get_new_cutout(50, 50, scale=0.089)\n",
    "\n",
    "        # plot the new image cutout\n",
    "        im.plot()\n",
    "        plt.savefig('SPECIFY DIR FOR IMAGES HERE'+gal_ids[i]+'.png')\n",
    "        plt.close()\n",
    "        plt.close()\n",
    "    except:\n",
    "        print('could not get image for galaxy: ',gal_ids[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7d1d22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10081/10081 [08:43<00:00, 19.26it/s]\n"
     ]
    }
   ],
   "source": [
    "images= []\n",
    "shap_map_mass =[]\n",
    "shap_map_sfr = []\n",
    "shap_map_d4000 = []\n",
    "sfh =[]\n",
    "category =[]\n",
    "\n",
    "for i in tqdm(manga_id):\n",
    "    images.append(load_image_data(i))\n",
    "    sfh.append(find_file_txt(i,'/home/juanpabloalfonzo/Documents/Manga CNNs/SFH (DR17)/True/Data Arrays/Train','/home/juanpabloalfonzo/Documents/Manga CNNs/SFH (DR17)/True/Data Arrays/Test'))\n",
    "    shap_map_mass.append(find_file(i+'.npy','/home/juanpabloalfonzo/Documents/Manga CNNs/SHAP-Maps/Mass/Train','/home/juanpabloalfonzo/Documents/Manga CNNs/SHAP-Maps/Mass/Test'))\n",
    "    shap_map_sfr.append(find_file(i+'.npy','/home/juanpabloalfonzo/Documents/Manga CNNs/SHAP-Maps/SFR/Train','/home/juanpabloalfonzo/Documents/Manga CNNs/SHAP-Maps/SFR/Test'))\n",
    "    shap_map_d4000.append(find_file(i+'.npy','/home/juanpabloalfonzo/Documents/Manga CNNs/SHAP-Maps/D4000/Train','/home/juanpabloalfonzo/Documents/Manga CNNs/SHAP-Maps/D4000/Test'))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157496d4",
   "metadata": {},
   "source": [
    "Getting Predictions from Chain CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa24990d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10081/10081 [02:24<00:00, 69.67it/s]\n",
      "100%|██████████| 10081/10081 [02:26<00:00, 68.69it/s]\n",
      "100%|██████████| 10081/10081 [02:26<00:00, 68.86it/s]\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "model_used = 'ResNet50_log_t50_chain_90_10'\n",
    "model_mass = models.resnet50(weights=None)\n",
    "model_mass.fc = nn.Linear(2048, 1)\n",
    "model_mass = nn.DataParallel(model_mass,device_ids=(0,1))\n",
    "model_mass.load_state_dict(torch.load(work_dir+'models/Mass_'+model_used+'.pytorch'),strict=True)#strict is set to false since it was trained on multiple GPUs it causes an error when loaded on the model that is not on multiple GPUs yet\n",
    "                                                                                                # DO NOT DO THIS!! MESSES WITH THE MODEL PREDECTIONS HEAVILY\n",
    "model_mass.eval()\n",
    "\n",
    "model_sfr = models.resnet50(weights='ResNet50_Weights.IMAGENET1K_V1')\n",
    "model_sfr.conv1 = nn.Conv2d(4, 64, kernel_size=7, stride=2, padding=3,bias=False)\n",
    "model_sfr.fc = nn.Linear(2048, 1)\n",
    "model_sfr = nn.DataParallel(model_sfr,device_ids=(0,1))\n",
    "model_sfr.load_state_dict(torch.load(work_dir+'models/SFR_'+model_used+'.pytorch'),strict=True)\n",
    "model_sfr.eval()\n",
    "\n",
    "model_used = 'd4000_chain'\n",
    "model_d4000 = models.resnet50(weights='ResNet50_Weights.IMAGENET1K_V1')\n",
    "model_d4000.conv1 = nn.Conv2d(5, 64, kernel_size=7, stride=2, padding=3,bias=False)\n",
    "model_d4000.fc = nn.Linear(2048, 1)\n",
    "model_d4000 = nn.DataParallel(model_d4000,device_ids=(0,1))\n",
    "model_d4000.load_state_dict(torch.load(work_dir+'models/d4000_'+model_used+'.pytorch'),strict=True)\n",
    "model_d4000.eval()\n",
    "\n",
    "\n",
    "model_mass, model_sfr, model_d4000 = model_mass.to(device), model_sfr.to(device), model_d4000.to(device)\n",
    "\n",
    "\n",
    "pred_mass = []\n",
    "\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "for i in tqdm(range(len(images))):\n",
    "    with torch.no_grad():\n",
    "        image_tensor = torch.ones((1,3,256,256))\n",
    "        image_tensor[0,:,:,:] = transform(images[i])\n",
    "        image_tensor = image_tensor.float().to('cuda')\n",
    "        pred = model_mass(image_tensor)\n",
    "        pred = pred.detach().cpu().numpy()\n",
    "        pred_mass.append(pred[0][0])\n",
    "\n",
    "pred_sfr = []\n",
    "for i in tqdm(range(len(images))):\n",
    "    with torch.no_grad():\n",
    "        image_tensor = torch.ones((1,3,256,256))\n",
    "        image_tensor[0,:,:,:] = transform(images[i])\n",
    "        pred_mass_tensor = torch.ones((1,1,256,256))*pred_mass[i]\n",
    "        image_mass_tensor = torch.concat((image_tensor,pred_mass_tensor),1)\n",
    "        image_mass_tensor = image_mass_tensor.float().to('cuda')\n",
    "        pred = model_sfr(image_mass_tensor)\n",
    "        pred = pred.detach().cpu().numpy()\n",
    "        pred_sfr.append(pred[0][0])\n",
    "\n",
    "pred_d4000 =[]\n",
    "for i in tqdm(range(len(images))):\n",
    "    with torch.no_grad():\n",
    "        image_tensor = torch.ones((1,3,256,256))\n",
    "        image_tensor[0,:,:,:] = transform(images[i])\n",
    "        pred_mass_tensor = torch.ones((1,1,256,256))*pred_mass[i]\n",
    "        image_mass_tensor = torch.concat((image_tensor,pred_mass_tensor),1)\n",
    "        pred_sfr_tensor = torch.ones((1,1,256,256))*pred_sfr[i]\n",
    "        image_mass_sfr_tensor = torch.concat((image_mass_tensor,pred_sfr_tensor),1)\n",
    "        image_mass_sfr_tensor = image_mass_sfr_tensor.float().to('cuda')\n",
    "        pred = model_d4000(image_mass_sfr_tensor)\n",
    "        pred = pred.detach().cpu().numpy()\n",
    "        pred_d4000.append(pred[0][0])\n",
    "\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc9056d",
   "metadata": {},
   "source": [
    "# Generating the Final Catalogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca406ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'mangaid':manga_id, 'log_mstar':log_mstar, 'log_sfr': log_sfr, 'redshift':redshift, 'redshift_gz':redshift_gz, 'sersic_n':sersic_n, 't50_Pipe3D':t50, 't50_model':t50_output,\n",
    "      'd4000':d4000, 'Av':Av, 'Z':Z, 'spirals':spirals, 'bars': bars, 'irregular_features':irregular_features, 'edge_on':edge_on,'bulge':bulge,\n",
    "       'RA_Pipe3D':RA_pipe3d, 'DEC_Pipe3D': DEC_pipe3d, 'RA_gz':RA_gz, 'DEC_gz':DEC_gz, 'smooth':smooth, 'merger_gz':merger_gz, 'p_merger':p_merger,'over_density':over_density,\n",
    "         'z_completeness':z_completeness, 'images':images, 'shap_map_mass':shap_map_mass, 'shap_map_sfr':shap_map_sfr,'shap_map_d4000':shap_map_d4000, \n",
    "         'split':category , 'pred_mstar':pred_mass,'pred_sfr':pred_sfr, 'pred_d4000':pred_d4000, 'sfh':sfh}\n",
    "\n",
    "manga_cat= pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "044408d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39m'DataFrame' type not understood, data is serialized:\u001b[0m \u001b[0;36m(SerializedWarning)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas 1.4.4\n"
     ]
    }
   ],
   "source": [
    "hickle.dump(manga_cat,'SHAP_Map_Labels_MaNGA_extra.cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8ce7c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalars = {'mangaid':manga_id, \n",
    "'log_mstar':log_mstar, \n",
    "'log_sfr': log_sfr, \n",
    "'redshift':redshift, \n",
    "'redshift_gz':redshift_gz, \n",
    "'sersic_n':sersic_n, \n",
    "'t50_Pipe3D':t50, \n",
    "'t50_model':t50_output,\n",
    "'d4000':d4000, \n",
    "'Av':Av, \n",
    "'Z':Z, \n",
    "'spirals':spirals, \n",
    "'bars': bars, \n",
    "'irregular_features':irregular_features, \n",
    "'edge_on':edge_on,\n",
    "'bulge':bulge,\n",
    "'RA_Pipe3D':RA_pipe3d, \n",
    "'DEC_Pipe3D': DEC_pipe3d, \n",
    "'RA_gz':RA_gz, \n",
    "'DEC_gz':DEC_gz, \n",
    "'smooth':smooth, \n",
    "'merger_gz':merger_gz, \n",
    "'p_merger':p_merger,\n",
    "'over_density':over_density,\n",
    "'z_completeness':z_completeness,\n",
    "'split':category,\n",
    "'pred_mstar':pred_mass,\n",
    "'pred_sfr':pred_sfr,\n",
    "'pred_d4000':pred_d4000,\n",
    "'sfh':sfh}\n",
    "\n",
    "scalars = pd.DataFrame(scalars)\n",
    "\n",
    "hickle.dump(scalars,'/home/juanpabloalfonzo/Documents/Manga CNNs/Catalogues/scalars_extra.cat')\n",
    "\n",
    "images_cat = {'mangaid':manga_id, 'images':images}\n",
    "images_cat = pd.DataFrame(images_cat)\n",
    "hickle.dump(images_cat,'/home/juanpabloalfonzo/Documents/Manga CNNs/Catalogues/images_extra.cat')\n",
    "\n",
    "shap_mass_cat = {'mangaid':manga_id, 'shap_map_mass':shap_map_mass}\n",
    "shap_mass_cat = pd.DataFrame(shap_mass_cat)\n",
    "hickle.dump(shap_mass_cat,'/home/juanpabloalfonzo/Documents/Manga CNNs/Catalogues/shap_mass_extra.cat')\n",
    "\n",
    "shap_sfr_cat = {'mangaid':manga_id, 'shap_map_mass':shap_map_sfr}\n",
    "shap_sfr_cat = pd.DataFrame(shap_sfr_cat)\n",
    "hickle.dump(shap_sfr_cat,'/home/juanpabloalfonzo/Documents/Manga CNNs/Catalogues/shap_sfr_extra.cat')\n",
    "\n",
    "shap_d4000_cat = {'mangaid':manga_id, 'shap_map_mass':shap_map_d4000}\n",
    "shap_d4000_cat = pd.DataFrame(shap_d4000_cat)\n",
    "hickle.dump(shap_d4000_cat,'/home/juanpabloalfonzo/Documents/Manga CNNs/Catalogues/shap_d4000_extra.cat')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "10a03494b4f35960f7ac7a0aa27c3484df1c156e3130f7b49c4453c0322280c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
