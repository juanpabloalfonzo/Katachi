{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "02ddf0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dense_basis as db\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, time, shutil, hickle\n",
    "from tqdm import tqdm\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(font_scale=1.8)\n",
    "sns.set_style('white')\n",
    "import hickle\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "\n",
    "import sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image as image_PIL\n",
    "from PIL import Image, ImageOps\n",
    "import PIL\n",
    "from PIL import ImageShow\n",
    "from astropy.io import fits\n",
    "\n",
    "from zoobot.pytorch.estimators import define_model as ZoobotModel\n",
    "\n",
    "import shap\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c1b472ca",
   "metadata": {},
   "source": [
    "# Data Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b3b01a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = 'INSTERT DIRECTORY OF THE GITCLONED FOLDER HERE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3c261592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(src_image, size=(256,256), bg_color=\"black\"): \n",
    "    \n",
    "    # resize the image so the longest dimension matches our target size\n",
    "    src_image.thumbnail(size, Image.ANTIALIAS)\n",
    "    \n",
    "    # Create a new square background image\n",
    "    new_image = Image.new(\"RGB\", size, bg_color)\n",
    "    \n",
    "    # Paste the resized image into the center of the square background\n",
    "    new_image.paste(src_image, (int((size[0] - src_image.size[0]) / 2), int((size[1] - src_image.size[1]) / 2)))\n",
    "  \n",
    "    # return the resized image\n",
    "    return new_image\n",
    "\n",
    "def load_image_data(idlist, size=(256,256), bg_color=\"black\"):\n",
    "    \n",
    "    images = []\n",
    "    for gal_id in tqdm(idlist):\n",
    "        #img = plt.imread('images/'+gal_id+'.png')\n",
    "        img = Image.open(work_dir+'images (DR17)/'+gal_id+'.png')\n",
    "        img_sized = resize_image(img, size=size, bg_color=bg_color)\n",
    "        images.append(img_sized)\n",
    "    return images\n",
    "\n",
    "class MaNGAdataset(Dataset):\n",
    "    \"\"\"images and labels for CNN\"\"\"\n",
    "    \n",
    "    def __init__(self, manga_cat, galmask, transform = None):\n",
    "        \n",
    "        gal_ids = manga_cat['manga_id']\n",
    "        gal_ids = np.array(gal_ids,dtype=str)[galmask]\n",
    "        gal_mass = manga_cat['log_mstar'][galmask]\n",
    "        #gal_mass_scaled = (gal_mass - 9)/4\n",
    "        gal_mass_scaled = gal_mass\n",
    "        gal_sfr = manga_cat['log_sfr'][galmask]\n",
    "        gal_z = manga_cat['redshift'][galmask]\n",
    "        gal_n = manga_cat['sersic_n'][galmask]\n",
    "        gal_t50_pipe3d = np.log10(manga_cat['t50_pipe3d'])[galmask]\n",
    "        gal_t50_model = np.log10(manga_cat['t50_model'])[galmask]\n",
    "        gal_d4000 = manga_cat['d4000'][galmask]\n",
    "        gal_spirals = manga_cat['spirals'][galmask]\n",
    "        gal_bars = manga_cat['bars'][galmask]\n",
    "        gal_bulge = manga_cat['bulge'][galmask]\n",
    "        gal_edge_on = manga_cat['edge_on'][galmask]\n",
    "        gal_irregular_features = manga_cat['irregular_features'][galmask]\n",
    "\n",
    "        # good_index = np.where(gal_sfr != -np.inf)[0]\n",
    "        good_index = np.where(np.array(gal_d4000,dtype=str) != 'nan')[0] #cleaning out nan values of d4000 \n",
    "\n",
    "        gal_ids = gal_ids[good_index]\n",
    "        gal_mass = gal_mass[good_index]\n",
    "        gal_sfr = gal_sfr[good_index]\n",
    "        gal_z = gal_z[good_index]\n",
    "        gal_n = gal_n[good_index]\n",
    "        gal_t50_pipe3d = gal_t50_pipe3d[good_index]\n",
    "        gal_t50_model = gal_t50_model[good_index]\n",
    "        gal_d4000 = gal_d4000[good_index]\n",
    "        gal_spirals = gal_spirals[good_index]\n",
    "        gal_bulge = gal_bulge[good_index]\n",
    "        gal_bars = gal_bars[good_index]\n",
    "        gal_edge_on = gal_edge_on[good_index]\n",
    "        gal_irregular_features = gal_irregular_features[good_index]\n",
    "\n",
    "\n",
    "        ###########CLASSIC CLASSES#######################\n",
    "\n",
    "        bars=np.linspace(np.min(gal_sfr), np.max(gal_sfr), num=11) #Number of classes set here (+1), default was 20 \n",
    "        sfr_cat = np.zeros_like(gal_sfr)\n",
    "        for i in range(len(bars)-1):\n",
    "            sfr_cat[(gal_sfr > bars[i]) & (gal_sfr < bars[i+1])]=int(i)\n",
    "        sfr_cat[gal_sfr > bars[len(bars)-1]] = int(len(bars)-1)\n",
    "\n",
    "        ########################NEW MORE EVENLY DISTRIBUTED CLASSES###################\n",
    "        \n",
    "        # bars=[-6,-2.5,-2,-1.7,-1.5,-1.2,-0.9,-0.7,-0.4,-0.1,0.1,0.9]\n",
    "        # sfr_cat = np.zeros_like(gal_sfr)\n",
    "        # for i in range(len(bars)-1):\n",
    "        #     sfr_cat[(gal_sfr > bars[i]) & (gal_sfr < bars[i+1])]=int(i)\n",
    "        # sfr_cat[gal_sfr > bars[len(bars)-1]] = int(len(bars)-1)\n",
    "      \n",
    "        self.image = load_image_data(gal_ids)\n",
    "        self.mangaid = gal_ids\n",
    "        self.mstar = gal_mass\n",
    "        self.mstar_class = gal_mass\n",
    "        self.sfr = sfr_cat\n",
    "        self.z = gal_z\n",
    "        self.n = gal_n\n",
    "        #self.c = ((gal_mass - 6)*3 - 1).astype(int)\n",
    "        self.c = sfr_cat.astype(int)\n",
    "        self.transform = transform\n",
    "        self.sfr_value = gal_sfr\n",
    "        self.t50_pipe3d = gal_t50_pipe3d\n",
    "        self.t50_model = gal_t50_model\n",
    "        self.d4000 = gal_d4000\n",
    "        self.spirals=gal_spirals\n",
    "        self.bars = gal_bars\n",
    "        self.bulge = gal_bulge\n",
    "        self.edge_on = gal_edge_on\n",
    "        self.irregular_features = gal_irregular_features\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.mstar)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "    \n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        sample = {'image': self.image[idx],\n",
    "                'mass': self.mstar[idx],\n",
    "                'z':self.z[idx],\n",
    "                'n':self.n[idx],\n",
    "                'sfr_class':self.sfr[idx],\n",
    "                'mangaid':self.mangaid[idx],\n",
    "                'sfr':self.sfr_value[idx],\n",
    "                't50_pipe3d':self.t50_pipe3d[idx],\n",
    "                't50_model':self.t50_model[idx],\n",
    "                'd4000':self.d4000[idx],\n",
    "                'spirals':self.spirals[idx],\n",
    "                'bars':self.bars[idx],\n",
    "                'bulge':self.bulge[idx],\n",
    "                'edge_on':self.edge_on[idx],\n",
    "                'irregular_features':self.irregular_features[idx]}\n",
    "        \n",
    "        if self.transform:\n",
    "            sample['image'] = self.transform(sample['image'])\n",
    "\n",
    "            \n",
    "            \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c93408aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this if you want both dataloaders to maintain the same order whenever they are iterated \n",
    "\n",
    "# train_loader = hickle.load(work_dir+'dataloaders/Train_Manga_DR17_log_t50_90_10_NO_SHUFFLE')\n",
    "# val_loader = hickle.load(work_dir+'dataloaders/Test_Manga_DR17_log_t50_90_10')\n",
    "\n",
    "#d4000 loaders\n",
    "# train_loader = hickle.load(work_dir+'dataloaders/Train_Manga_DR17_d4000_NO_SHUFFLE')\n",
    "# val_loader = hickle.load(work_dir+'dataloaders/Test_Manga_DR17_d4000')\n",
    "\n",
    "# #d4000 loaders with no transformations applied to the images \n",
    "train_loader = hickle.load(work_dir+'dataloaders/Train_Manga_DR17_Morph_for_SHAP_MAPS')\n",
    "val_loader = hickle.load(work_dir+'dataloaders/Test_Manga_DR17_Morph_for_SHAP_MAPS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7ccf3ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_ids = []\n",
    "mass = []\n",
    "sfr = []\n",
    "t50_pipe3d = []\n",
    "t50_model = []\n",
    "images = []\n",
    "z = []\n",
    "d4000 = []\n",
    "spirals = []\n",
    "bars = []\n",
    "bulge = []\n",
    "edge_on = []\n",
    "irregular_features = []\n",
    "\n",
    "data_sample = train_loader\n",
    "\n",
    "for batch_idx, temp in enumerate(data_sample):\n",
    "    train_ids.append(temp['mangaid'])\n",
    "    mass.append(temp['mass'])\n",
    "    sfr.append(temp['sfr'])\n",
    "    t50_pipe3d.append(temp['t50_pipe3d'])\n",
    "    t50_model.append(temp['t50_model'])\n",
    "    images.append(temp['image'])\n",
    "    z.append(temp['z'])\n",
    "    d4000.append(temp['d4000'])\n",
    "    spirals.append(temp['spirals'])\n",
    "    bars.append(temp['bars'])\n",
    "    bulge.append(temp['bulge'])\n",
    "    edge_on.append(temp['edge_on'])\n",
    "    irregular_features.append(temp['irregular_features'])\n",
    "\n",
    "\n",
    "incomplete_batch_id = len(train_ids) - 1\n",
    "remainder = len(train_ids[incomplete_batch_id])\n",
    "\n",
    "total_values = (len(train_ids) * batch_size) - (batch_size - remainder)\n",
    "\n",
    "train_ids_list = []\n",
    "train_mass_list = []\n",
    "train_sfr_list = []\n",
    "train_t50_pipe3d_list = []\n",
    "train_t50_model_list = []\n",
    "train_images_list = []\n",
    "train_z_list = []\n",
    "train_d4000_list = []\n",
    "train_spirals_list = []\n",
    "train_bars_list = []\n",
    "train_bulge_list = []\n",
    "train_edge_on_list = []\n",
    "train_irregular_features_list = []\n",
    "\n",
    "k = 0\n",
    "while k < total_values:\n",
    "    for i in range(len(train_ids)):\n",
    "        if i < incomplete_batch_id:\n",
    "            for j in range(batch_size):\n",
    "                train_ids_list.append(train_ids[i][j])\n",
    "                train_mass_list.append(mass[i][j])\n",
    "                train_sfr_list.append(sfr[i][j])\n",
    "                train_t50_pipe3d_list.append(t50_pipe3d[i][j])\n",
    "                train_t50_model_list.append(t50_model[i][j])\n",
    "                train_images_list.append(images[i][j])\n",
    "                train_z_list.append(z[i][j])\n",
    "                train_d4000_list.append(d4000[i][j])\n",
    "                train_spirals_list.append(spirals[i][j])\n",
    "                train_bars_list.append(bars[i][j])\n",
    "                train_bulge_list.append(bulge[i][j])\n",
    "                train_edge_on_list.append(edge_on[i][j])\n",
    "                train_irregular_features_list.append(irregular_features[i][j])\n",
    "                k += 1\n",
    "        else:\n",
    "            for j in range(remainder):\n",
    "                train_ids_list.append(train_ids[i][j])\n",
    "                train_mass_list.append(mass[i][j])\n",
    "                train_sfr_list.append(sfr[i][j])\n",
    "                train_t50_pipe3d_list.append(t50_pipe3d[i][j])\n",
    "                train_t50_model_list.append(t50_model[i][j])\n",
    "                train_images_list.append(images[i][j])\n",
    "                train_z_list.append(z[i][j])\n",
    "                train_d4000_list.append(d4000[i][j])\n",
    "                train_spirals_list.append(spirals[i][j])\n",
    "                train_bars_list.append(bars[i][j])\n",
    "                train_bulge_list.append(bulge[i][j])\n",
    "                train_edge_on_list.append(edge_on[i][j])\n",
    "                train_irregular_features_list.append(irregular_features[i][j])\n",
    "                k += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ca9ae4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "val_ids = []\n",
    "mass = []\n",
    "sfr = []\n",
    "t50_pipe3d = []\n",
    "t50_model = []\n",
    "images = []\n",
    "z = []\n",
    "d4000 = []\n",
    "spirals = []\n",
    "bars = []\n",
    "bulge = []\n",
    "edge_on = []\n",
    "irregular_features = []\n",
    "\n",
    "data_sample = val_loader\n",
    "\n",
    "for batch_idx, temp in enumerate(data_sample):\n",
    "    val_ids.append(temp['mangaid'])\n",
    "    mass.append(temp['mass'])\n",
    "    sfr.append(temp['sfr'])\n",
    "    t50_pipe3d.append(temp['t50_pipe3d'])\n",
    "    t50_model.append(temp['t50_model'])\n",
    "    images.append(temp['image'])\n",
    "    z.append(temp['z'])\n",
    "    d4000.append(temp['d4000'])\n",
    "    spirals.append(temp['spirals'])\n",
    "    bars.append(temp['bars'])\n",
    "    bulge.append(temp['bulge'])\n",
    "    edge_on.append(temp['edge_on'])\n",
    "    irregular_features.append(temp['irregular_features'])\n",
    "\n",
    "\n",
    "incomplete_batch_id = len(val_ids) - 1\n",
    "remainder = len(val_ids[incomplete_batch_id])\n",
    "\n",
    "total_values = (len(val_ids) * batch_size) - (batch_size - remainder)\n",
    "\n",
    "test_ids_list = []\n",
    "test_mass_list = []\n",
    "test_sfr_list = []\n",
    "test_t50_pipe3d_list = []\n",
    "test_t50_model_list = []\n",
    "test_images_list = []\n",
    "test_z_list = []\n",
    "test_d4000_list = []\n",
    "test_spirals_list = []\n",
    "test_bars_list = []\n",
    "test_bulge_list = []\n",
    "test_edge_on_list = []\n",
    "test_irregular_features_list = []\n",
    "\n",
    "k = 0\n",
    "while k < total_values:\n",
    "    for i in range(len(val_ids)):\n",
    "        if i < incomplete_batch_id:\n",
    "            for j in range(batch_size):\n",
    "                test_ids_list.append(val_ids[i][j])\n",
    "                test_mass_list.append(mass[i][j])\n",
    "                test_sfr_list.append(sfr[i][j])\n",
    "                test_t50_pipe3d_list.append(t50_pipe3d[i][j])\n",
    "                test_t50_model_list.append(t50_model[i][j])\n",
    "                test_images_list.append(images[i][j])\n",
    "                test_z_list.append(z[i][j])\n",
    "                test_d4000_list.append(d4000[i][j])\n",
    "                test_spirals_list.append(spirals[i][j])\n",
    "                test_bars_list.append(bars[i][j])\n",
    "                test_bulge_list.append(bulge[i][j])\n",
    "                test_edge_on_list.append(edge_on[i][j])\n",
    "                test_irregular_features_list.append(irregular_features[i][j])\n",
    "                k += 1\n",
    "        else:\n",
    "            for j in range(remainder):\n",
    "                test_ids_list.append(val_ids[i][j])\n",
    "                test_mass_list.append(mass[i][j])\n",
    "                test_sfr_list.append(sfr[i][j])\n",
    "                test_t50_pipe3d_list.append(t50_pipe3d[i][j])\n",
    "                test_t50_model_list.append(t50_model[i][j])\n",
    "                test_images_list.append(images[i][j])\n",
    "                test_z_list.append(z[i][j])\n",
    "                test_d4000_list.append(d4000[i][j])\n",
    "                test_spirals_list.append(spirals[i][j])\n",
    "                test_bars_list.append(bars[i][j])\n",
    "                test_bulge_list.append(bulge[i][j])\n",
    "                test_edge_on_list.append(edge_on[i][j])\n",
    "                test_irregular_features_list.append(irregular_features[i][j])\n",
    "                k += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "713bc030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9414"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ids_list)+len(test_ids_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28328924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# work_dir = '/home/juanpabloalfonzo/Documents/Manga CNNs/'\n",
    "model_used = 'ResNet50_log_t50_chain_90_10'\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "model_used = 'ResNet50_log_t50_chain_90_10'\n",
    "model_mass = models.resnet50(weights=None)\n",
    "model_mass.fc = nn.Linear(2048, 1)\n",
    "model_mass = nn.DataParallel(model_mass,device_ids=(0,1))\n",
    "model_mass.load_state_dict(torch.load(work_dir+'models/Mass_'+model_used+'.pytorch'),strict=True)#strict is set to false since it was trained on multiple GPUs it causes an error when loaded on the model that is not on multiple GPUs yet\n",
    "                                                                                                # DO NOT DO THIS!! MESSES WITH THE MODEL PREDECTIONS HEAVILY\n",
    "model_mass.eval()\n",
    "\n",
    "model_sfr = models.resnet50(weights='ResNet50_Weights.IMAGENET1K_V1')\n",
    "model_sfr.conv1 = nn.Conv2d(4, 64, kernel_size=7, stride=2, padding=3,bias=False)\n",
    "model_sfr.fc = nn.Linear(2048, 1)\n",
    "model_sfr = nn.DataParallel(model_sfr,device_ids=(0,1))\n",
    "model_sfr.load_state_dict(torch.load(work_dir+'models/SFR_'+model_used+'.pytorch'),strict=True)\n",
    "model_sfr.eval()\n",
    "\n",
    "model_used = 'd4000_chain'\n",
    "model_t50 = models.resnet50(weights='ResNet50_Weights.IMAGENET1K_V1')\n",
    "model_t50.conv1 = nn.Conv2d(5, 64, kernel_size=7, stride=2, padding=3,bias=False)\n",
    "model_t50.fc = nn.Linear(2048, 1)\n",
    "model_t50 = nn.DataParallel(model_t50,device_ids=(0,1))\n",
    "model_t50.load_state_dict(torch.load(work_dir+'models/d4000_'+model_used+'.pytorch'),strict=True)\n",
    "model_t50.eval()\n",
    "\n",
    "\n",
    "\n",
    "model_mass, model_sfr, model_t50 = model_mass.to(device), model_sfr.to(device), model_t50.to(device)\n",
    "\n",
    "\n",
    "model_d4000 = models.resnet50(weights=None)\n",
    "model_d4000.fc = nn.Linear(2048, 1)\n",
    "model_d4000.load_state_dict(torch.load(work_dir+'models/d4000.pytorch'),strict=True)\n",
    "model_d4000.to('cuda')\n",
    "model_d4000.eval()\n",
    "\n",
    "model_sfr_solo = models.resnet50(weights='ResNet50_Weights.IMAGENET1K_V1')\n",
    "model_sfr_solo.fc = nn.Linear(2048,1)\n",
    "model_sfr_solo.load_state_dict(torch.load(work_dir+'models/sfr_solo.pytorch'),strict=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4ff04020",
   "metadata": {},
   "source": [
    "# D4000 to t50 Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ddf9a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_d4000(lam, spec):\n",
    "    # this is probably not quite correct, \n",
    "    # look up the defn in a paper and modify accordingly\n",
    "    # also make sure spec is in the right units!!!\n",
    "    \n",
    "    lam_mask1 = (lam > 3850) & (lam < 3950)\n",
    "    lam_mask2 = (lam > 4100) & (lam < 4200)\n",
    "    dn4000 = np.nanmean(spec[lam_mask2]) / np.nanmean(spec[lam_mask1])\n",
    "    return dn4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8b648feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dn4000_for_synthetic_obs(mstar, sfr, t50, Av, Z, zval):\n",
    "    sfh_tuple = np.array([mstar, sfr, 1.0, t50])\n",
    "    specdetails = [sfh_tuple, Av, Z, zval]\n",
    "    lam, spec = db.makespec(specdetails, priors, db.mocksp, db.cosmo, return_spec = True, peraa=True)\n",
    "    dn4000 = calc_d4000(lam, spec)\n",
    "    return dn4000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc779162",
   "metadata": {},
   "source": [
    "# Making Mock Observations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca9411a3",
   "metadata": {},
   "source": [
    "Distrubution of MaNGA Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "def8cdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting additional data to create mock MaNGA Spectrum from PIPE3D VAC\n",
    "data = fits.open('/home/juanpabloalfonzo/Documents/Manga CNNs/SDSS17Pipe3D_v3_1_1.fits')\n",
    "table = data[1]\n",
    "\n",
    "Av=[]\n",
    "Z=[]\n",
    "manga_sfr =[]\n",
    "manga_mass = []\n",
    "for i in range(len(table.data)):\n",
    "    Av.append(table.data[i][173])\n",
    "    Z.append(table.data[i][28])\n",
    "    manga_mass.append(table.data[i][12])\n",
    "    manga_sfr.append(table.data[i][7])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960effbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size= 10000\n",
    "\n",
    "t50_vals = np.random.uniform(low = 10**(np.min([np.min(train_t50_list),np.min(test_t50_list)]))/13.6, high =10**(np.max([np.max(train_t50_list),np.max(test_t50_list)]))/13.6,size=(sample_size,))\n",
    "# t50_vals = np.random.uniform(low = 0.05, high = 0.81, size=(1000,))\n",
    "# mstar_vals = np.random.uniform(low = np.min([np.min(train_mass_list),np.min(test_mass_list)]), high =np.max([np.max(train_mass_list),np.max(test_mass_list)]), size=(sample_size,))\n",
    "mstar_vals = np.random.uniform(8,12.5,size=(sample_size,))\n",
    "# sfr_vals = np.random.uniform(low = np.min([np.min(train_sfr_list),np.min(test_sfr_list)]), high =np.max([np.max(train_sfr_list),np.max(test_sfr_list)]), size=(sample_size,))\n",
    "sfr_vals = np.random.uniform(-4,2.5,size=(sample_size,))\n",
    "Av_vals = np.random.uniform(low = np.nanmin(Av), high =np.nanmax(Av), size=(sample_size,))\n",
    "Z_vals = np.random.uniform(low = np.nanmin(Z), high =np.nanmax(Z), size=(sample_size,))\n",
    "redshift = np.random.uniform(low = np.min([np.min(train_z_list),np.min(test_z_list)]), high =np.max([np.max(train_z_list),np.max(test_z_list)]), size=(sample_size,))\n",
    "\n",
    "priors = db.Priors()\n",
    "\n",
    "\n",
    "dn4000_vals = np.zeros_like(t50_vals)\n",
    "for i in db.tqdm(range(len(t50_vals))):\n",
    "    dn4000_vals[i] = make_dn4000_for_synthetic_obs(mstar_vals[i], sfr_vals[i], t50_vals[i], Av[i], Z[i], redshift[i])\n",
    "    \n",
    "plt.plot(t50_vals, dn4000_vals,'.')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea9cc7c6",
   "metadata": {},
   "source": [
    "# T50 Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "40de6161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the one-layer linear neural network class\n",
    "class LinearNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LinearNet, self).__init__()\n",
    "        self.linear_in = nn.Linear(input_size, hidden_size)\n",
    "        self.linear_out = nn.Linear(hidden_size, output_size)\n",
    "        self.linear = nn.Linear(hidden_size,hidden_size)\n",
    "        self.activation = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # print(x.size())\n",
    "        out = self.linear_in(x)\n",
    "        # print(out.size())\n",
    "        out = self.activation(out)\n",
    "        out = self.linear(out)\n",
    "        out = self.activation(out)\n",
    "        out = self.linear(out)\n",
    "        out = self.activation(out)\n",
    "        out = self.linear(out)\n",
    "        out = self.activation(out)\n",
    "        # out = self.linear(out)\n",
    "        # out = self.activation(out)\n",
    "        out = self.linear_out(out)\n",
    "        return out\n",
    "\n",
    "# Example usage\n",
    "input_size = 2\n",
    "hidden_size = 100\n",
    "output_size = 1\n",
    "\n",
    "\n",
    "# Create an instance of the LinearNet\n",
    "d4000_to_t50 = LinearNet(input_size, hidden_size, output_size).to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dca800b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 100/400 [01:31<04:42,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/400], Loss: 0.0325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 200/400 [03:03<03:06,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/400], Loss: 0.0228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 300/400 [04:35<01:31,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [300/400], Loss: 0.0369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [05:59<00:00,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [400/400], Loss: 0.0158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define loss function and optimizer\n",
    "device = 'cuda'\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(d4000_to_t50.parameters(), lr=0.001)\n",
    "\n",
    "t50_tensor = torch.tensor(t50_vals).unsqueeze(1).to('cuda')\n",
    "dn4000_tensor = torch.tensor(dn4000_vals).unsqueeze(1).to('cuda')\n",
    "\n",
    "input_data = torch.tensor(dn4000_vals, dtype=torch.float32).unsqueeze(1)\n",
    "input_data1 = torch.tensor(mstar_vals, dtype=torch.float32).unsqueeze(1)\n",
    "input_data2 = torch.tensor(sfr_vals, dtype=torch.float32).unsqueeze(1)\n",
    "target_data = torch.tensor(t50_vals, dtype=torch.float32).unsqueeze(1) \n",
    "\n",
    "dataset = TensorDataset(input_data, input_data1, input_data2, target_data)\n",
    "\n",
    "train_ratio = 0.8\n",
    "\n",
    "# Calculate the number of samples for train and test\n",
    "num_samples = len(dataset)\n",
    "num_train = int(train_ratio * num_samples)\n",
    "num_test = num_samples - num_train\n",
    "\n",
    "# Split the dataset into train and test\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [num_train, num_test])\n",
    "\n",
    "batch_size=32\n",
    "# Create train and test loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# Training loop\n",
    "epochs = 400\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    # Set model to training mode\n",
    "    d4000_to_t50.train()\n",
    "\n",
    "    # Iterate over the train loader\n",
    "    for batch in train_loader:\n",
    "        inputs0, inputs1, inputs2, targets = batch\n",
    "        inputs = torch.stack((inputs0,inputs2-inputs1),dim=1).reshape(batch_size,input_size)\n",
    "        inputs = inputs.reshape(inputs.shape[0],inputs.shape[1])\n",
    "        # .swapaxes(1,2)\n",
    "        # inputs = inputs0\n",
    "        # print(inputs.size())\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets\n",
    "        # print(targets.size())\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = d4000_to_t50(inputs)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Print progress\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, epochs, loss.item()))\n",
    "\n",
    "    # Testing loop\n",
    "    with torch.no_grad():\n",
    "        # Set model to evaluation mode\n",
    "        d4000_to_t50.eval()\n",
    "\n",
    "        test_loss = 0.0\n",
    "        total_samples = 0\n",
    "\n",
    "        for batch in test_loader:\n",
    "            inputs0, inputs1, inputs2, targets = batch\n",
    "            inputs = torch.stack((inputs0,inputs2-inputs1),dim=1)\n",
    "            inputs = inputs.reshape(inputs.shape[0],inputs.shape[1])\n",
    "            # inputs = inputs0\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets\n",
    "            targets = targets.to(device)\n",
    "\n",
    "\n",
    "            # Forward pass on test data\n",
    "            test_outputs = d4000_to_t50(inputs)\n",
    "\n",
    "            # Calculate test loss\n",
    "            batch_loss = criterion(test_outputs, targets)\n",
    "            test_loss += batch_loss.item() * len(inputs)\n",
    "            total_samples += len(inputs)\n",
    "\n",
    "        # Calculate and print the average test loss\n",
    "        average_test_loss = test_loss / total_samples\n",
    "        # print(\"Average Test Loss:\", average_test_loss)\n",
    "\n",
    "\n",
    "     \n",
    "       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
